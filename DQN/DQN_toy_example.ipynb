{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGZCbkComs6y"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhjKtkBimzfC"
      },
      "outputs": [],
      "source": [
        "# Define the custom environment\n",
        "class SimpleGridEnv:\n",
        "    def __init__(self, grid_size=5, target_position=(4, 4)):\n",
        "        self.grid_size = grid_size\n",
        "        self.target_position = target_position\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.agent_position = [0, 0]\n",
        "        return self.get_state()\n",
        "\n",
        "    def get_state(self):\n",
        "        return np.array(self.agent_position)\n",
        "\n",
        "    def step(self, action):\n",
        "        if action == 0:  # Up\n",
        "            self.agent_position[0] = max(0, self.agent_position[0] - 1)\n",
        "        elif action == 1:  # Down\n",
        "            self.agent_position[0] = min(self.grid_size - 1, self.agent_position[0] + 1)\n",
        "        elif action == 2:  # Left\n",
        "            self.agent_position[1] = max(0, self.agent_position[1] - 1)\n",
        "        elif action == 3:  # Right\n",
        "            self.agent_position[1] = min(self.grid_size - 1, self.agent_position[1] + 1)\n",
        "\n",
        "        reward = -1\n",
        "        done = False\n",
        "        if self.agent_position == list(self.target_position):\n",
        "            reward = 10\n",
        "            done = True\n",
        "\n",
        "        return self.get_state(), reward, done\n",
        "\n",
        "    def sample_action(self):\n",
        "        return random.randint(0, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pV8vpFkLm5zV"
      },
      "outputs": [],
      "source": [
        "# Define the DQN model\n",
        "class DQN(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(DQN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 64)\n",
        "        self.fc2 = nn.Linear(64, 64)\n",
        "        self.fc3 = nn.Linear(64, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        return self.fc3(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKmhkMe4m-8g"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "EPISODES = 500\n",
        "GAMMA = 0.99\n",
        "EPSILON = 1.0\n",
        "EPSILON_DECAY = 0.995\n",
        "EPSILON_MIN = 0.01\n",
        "LEARNING_RATE = 0.001\n",
        "BATCH_SIZE = 64\n",
        "MEMORY_SIZE = 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SaiEEi71nDcj"
      },
      "outputs": [],
      "source": [
        "# Replay buffer\n",
        "class ReplayMemory:\n",
        "    def __init__(self, capacity):\n",
        "        self.capacity = capacity\n",
        "        self.memory = []\n",
        "        self.position = 0\n",
        "\n",
        "    def push(self, transition):\n",
        "        if len(self.memory) < self.capacity:\n",
        "            self.memory.append(None)\n",
        "        self.memory[self.position] = transition\n",
        "        self.position = (self.position + 1) % self.capacity\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.memory, batch_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3dPHe-ynHHH"
      },
      "outputs": [],
      "source": [
        "def train_dqn():\n",
        "    global EPSILON  # Declare EPSILON as global so it can be modified\n",
        "    env = SimpleGridEnv()\n",
        "    state_dim = 2\n",
        "    action_dim = 4\n",
        "\n",
        "    dqn = DQN(state_dim, action_dim)\n",
        "    target_dqn = DQN(state_dim, action_dim)\n",
        "    target_dqn.load_state_dict(dqn.state_dict())\n",
        "\n",
        "    optimizer = optim.Adam(dqn.parameters(), lr=LEARNING_RATE)\n",
        "    memory = ReplayMemory(MEMORY_SIZE)\n",
        "\n",
        "    for episode in range(EPISODES):\n",
        "        state = env.reset()\n",
        "        total_reward = 0\n",
        "        path = [list(state)]  # Initialize path with starting position\n",
        "\n",
        "        for step in range(100):  # Limit steps per episode\n",
        "            # Epsilon-greedy action selection\n",
        "            if random.random() < EPSILON:\n",
        "                action = env.sample_action()\n",
        "            else:\n",
        "                state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
        "                with torch.no_grad():\n",
        "                    action = dqn(state_tensor).argmax().item()\n",
        "\n",
        "            next_state, reward, done = env.step(action)\n",
        "            memory.push((state, action, reward, next_state, done))\n",
        "\n",
        "            # Append the new position to the path\n",
        "            path.append(list(next_state))\n",
        "\n",
        "            state = next_state\n",
        "            total_reward += reward\n",
        "\n",
        "            if len(memory) >= BATCH_SIZE:\n",
        "                # Sample a batch from memory\n",
        "                batch = memory.sample(BATCH_SIZE)\n",
        "                batch_state, batch_action, batch_reward, batch_next_state, batch_done = zip(*batch)\n",
        "\n",
        "                batch_state = torch.FloatTensor(batch_state)\n",
        "                batch_action = torch.LongTensor(batch_action).unsqueeze(1)\n",
        "                batch_reward = torch.FloatTensor(batch_reward)\n",
        "                batch_next_state = torch.FloatTensor(batch_next_state)\n",
        "                batch_done = torch.FloatTensor(batch_done)\n",
        "\n",
        "                # Compute the target Q values\n",
        "                with torch.no_grad():\n",
        "                    next_q_values = target_dqn(batch_next_state).max(1)[0]\n",
        "                    target_q_values = batch_reward + GAMMA * next_q_values * (1 - batch_done)\n",
        "\n",
        "                # Get current Q values\n",
        "                current_q_values = dqn(batch_state).gather(1, batch_action).squeeze(1)\n",
        "\n",
        "                # Compute loss and optimize\n",
        "                loss = nn.MSELoss()(current_q_values, target_q_values)\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "        # Update the target network periodically\n",
        "        if episode % 10 == 0:\n",
        "            target_dqn.load_state_dict(dqn.state_dict())\n",
        "\n",
        "        # Decay epsilon\n",
        "        EPSILON = max(EPSILON_MIN, EPSILON * EPSILON_DECAY)\n",
        "\n",
        "        # Print the path every 20 episodes\n",
        "        if episode % 20 == 0:\n",
        "            print(f\"Episode {episode}, Path: {path}\")\n",
        "\n",
        "        print(f\"Episode {episode}, Total Reward: {total_reward}, Epsilon: {EPSILON}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDXFbItwnJjV",
        "outputId": "7adf3c23-f049-4c50-9c48-cd296723b6a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 0, Path: [[0, 0], [0, 1], [0, 0], [0, 0], [0, 0], [1, 0], [2, 0], [3, 0], [4, 0], [4, 1], [4, 0], [4, 0], [4, 0], [4, 1], [4, 2], [4, 1], [4, 0], [4, 1], [4, 1], [4, 2], [4, 2], [4, 3], [4, 4]]\n",
            "Episode 0, Total Reward: -11, Epsilon: 0.995\n",
            "Episode 1, Total Reward: -31, Epsilon: 0.990025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-ea314986d27f>:42: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  batch_state = torch.FloatTensor(batch_state)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 2, Total Reward: -25, Epsilon: 0.985074875\n",
            "Episode 3, Total Reward: -100, Epsilon: 0.9801495006250001\n",
            "Episode 4, Total Reward: -44, Epsilon: 0.9752487531218751\n",
            "Episode 5, Total Reward: -27, Epsilon: 0.9703725093562657\n",
            "Episode 6, Total Reward: -100, Epsilon: 0.9655206468094844\n",
            "Episode 7, Total Reward: -61, Epsilon: 0.960693043575437\n",
            "Episode 8, Total Reward: -53, Epsilon: 0.9558895783575597\n",
            "Episode 9, Total Reward: -100, Epsilon: 0.9511101304657719\n",
            "Episode 10, Total Reward: -68, Epsilon: 0.946354579813443\n",
            "Episode 11, Total Reward: -18, Epsilon: 0.9416228069143757\n",
            "Episode 12, Total Reward: -64, Epsilon: 0.9369146928798039\n",
            "Episode 13, Total Reward: -8, Epsilon: 0.9322301194154049\n",
            "Episode 14, Total Reward: -44, Epsilon: 0.9275689688183278\n",
            "Episode 15, Total Reward: -4, Epsilon: 0.9229311239742362\n",
            "Episode 16, Total Reward: -100, Epsilon: 0.918316468354365\n",
            "Episode 17, Total Reward: -58, Epsilon: 0.9137248860125932\n",
            "Episode 18, Total Reward: -10, Epsilon: 0.9091562615825302\n",
            "Episode 19, Total Reward: -11, Epsilon: 0.9046104802746175\n",
            "Episode 20, Path: [[0, 0], [0, 0], [0, 0], [0, 1], [0, 2], [1, 2], [1, 1], [1, 2], [2, 2], [3, 2], [3, 1], [3, 0], [3, 1], [3, 0], [3, 0], [4, 0], [4, 0], [4, 0], [4, 0], [4, 0], [3, 0], [4, 0], [4, 1], [3, 1], [4, 1], [4, 2], [4, 3], [4, 2], [4, 1], [4, 2], [4, 3], [3, 3], [4, 3], [3, 3], [2, 3], [3, 3], [4, 3], [4, 3], [4, 4]]\n",
            "Episode 20, Total Reward: -27, Epsilon: 0.9000874278732445\n",
            "Episode 21, Total Reward: -69, Epsilon: 0.8955869907338783\n",
            "Episode 22, Total Reward: -100, Epsilon: 0.8911090557802088\n",
            "Episode 23, Total Reward: -25, Epsilon: 0.8866535105013078\n",
            "Episode 24, Total Reward: -100, Epsilon: 0.8822202429488013\n",
            "Episode 25, Total Reward: -50, Epsilon: 0.8778091417340573\n",
            "Episode 26, Total Reward: -5, Epsilon: 0.8734200960253871\n",
            "Episode 27, Total Reward: -100, Epsilon: 0.8690529955452602\n",
            "Episode 28, Total Reward: -41, Epsilon: 0.8647077305675338\n",
            "Episode 29, Total Reward: -51, Epsilon: 0.8603841919146962\n",
            "Episode 30, Total Reward: -27, Epsilon: 0.8560822709551227\n",
            "Episode 31, Total Reward: 1, Epsilon: 0.851801859600347\n",
            "Episode 32, Total Reward: -25, Epsilon: 0.8475428503023453\n",
            "Episode 33, Total Reward: 0, Epsilon: 0.8433051360508336\n",
            "Episode 34, Total Reward: -8, Epsilon: 0.8390886103705794\n",
            "Episode 35, Total Reward: -61, Epsilon: 0.8348931673187264\n",
            "Episode 36, Total Reward: -49, Epsilon: 0.8307187014821328\n",
            "Episode 37, Total Reward: -22, Epsilon: 0.8265651079747222\n",
            "Episode 38, Total Reward: -39, Epsilon: 0.8224322824348486\n",
            "Episode 39, Total Reward: -5, Epsilon: 0.8183201210226743\n",
            "Episode 40, Path: [[0, 0], [0, 0], [0, 0], [0, 0], [0, 1], [1, 1], [1, 2], [2, 2], [1, 2], [0, 2], [0, 1], [0, 2], [0, 3], [1, 3], [2, 3], [2, 2], [1, 2], [2, 2], [3, 2], [3, 1], [3, 2], [3, 3], [3, 4], [2, 4], [2, 3], [2, 2], [2, 3], [1, 3], [1, 4], [2, 4], [1, 4], [1, 3], [2, 3], [2, 2], [2, 3], [3, 3], [4, 3], [4, 4]]\n",
            "Episode 40, Total Reward: -26, Epsilon: 0.8142285204175609\n",
            "Episode 41, Total Reward: -21, Epsilon: 0.810157377815473\n",
            "Episode 42, Total Reward: -43, Epsilon: 0.8061065909263957\n",
            "Episode 43, Total Reward: -30, Epsilon: 0.8020760579717637\n",
            "Episode 44, Total Reward: -13, Epsilon: 0.798065677681905\n",
            "Episode 45, Total Reward: -56, Epsilon: 0.7940753492934954\n",
            "Episode 46, Total Reward: -100, Epsilon: 0.7901049725470279\n",
            "Episode 47, Total Reward: -57, Epsilon: 0.7861544476842928\n",
            "Episode 48, Total Reward: -24, Epsilon: 0.7822236754458713\n",
            "Episode 49, Total Reward: -9, Epsilon: 0.778312557068642\n",
            "Episode 50, Total Reward: -44, Epsilon: 0.7744209942832988\n",
            "Episode 51, Total Reward: -67, Epsilon: 0.7705488893118823\n",
            "Episode 52, Total Reward: -9, Epsilon: 0.7666961448653229\n",
            "Episode 53, Total Reward: -28, Epsilon: 0.7628626641409962\n",
            "Episode 54, Total Reward: -8, Epsilon: 0.7590483508202912\n",
            "Episode 55, Total Reward: -23, Epsilon: 0.7552531090661897\n",
            "Episode 56, Total Reward: -7, Epsilon: 0.7514768435208588\n",
            "Episode 57, Total Reward: -15, Epsilon: 0.7477194593032545\n",
            "Episode 58, Total Reward: -2, Epsilon: 0.7439808620067382\n",
            "Episode 59, Total Reward: -6, Epsilon: 0.7402609576967045\n",
            "Episode 60, Path: [[0, 0], [0, 1], [1, 1], [1, 2], [0, 2], [0, 3], [0, 4], [0, 4], [0, 4], [0, 3], [1, 3], [1, 2], [1, 1], [1, 2], [1, 3], [1, 2], [1, 3], [0, 3], [0, 2], [0, 3], [1, 3], [2, 3], [3, 3], [3, 2], [3, 3], [2, 3], [2, 2], [1, 2], [1, 3], [2, 3], [2, 4], [2, 4], [2, 4], [2, 4], [1, 4], [2, 4], [2, 3], [2, 2], [1, 2], [1, 3], [1, 2], [1, 1], [0, 1], [1, 1], [1, 0], [2, 0], [1, 0], [1, 0], [0, 0], [0, 1], [0, 1], [1, 1], [1, 2], [1, 1], [2, 1], [3, 1], [4, 1], [3, 1], [4, 1], [4, 2], [3, 2], [4, 2], [4, 1], [4, 1], [4, 2], [4, 3], [4, 4]]\n",
            "Episode 60, Total Reward: -55, Epsilon: 0.736559652908221\n",
            "Episode 61, Total Reward: -16, Epsilon: 0.7328768546436799\n",
            "Episode 62, Total Reward: -1, Epsilon: 0.7292124703704616\n",
            "Episode 63, Total Reward: -30, Epsilon: 0.7255664080186093\n",
            "Episode 64, Total Reward: 1, Epsilon: 0.7219385759785162\n",
            "Episode 65, Total Reward: -7, Epsilon: 0.7183288830986236\n",
            "Episode 66, Total Reward: -18, Epsilon: 0.7147372386831305\n",
            "Episode 67, Total Reward: -17, Epsilon: 0.7111635524897149\n",
            "Episode 68, Total Reward: -3, Epsilon: 0.7076077347272662\n",
            "Episode 69, Total Reward: -22, Epsilon: 0.7040696960536299\n",
            "Episode 70, Total Reward: -15, Epsilon: 0.7005493475733617\n",
            "Episode 71, Total Reward: -8, Epsilon: 0.697046600835495\n",
            "Episode 72, Total Reward: -8, Epsilon: 0.6935613678313175\n",
            "Episode 73, Total Reward: -22, Epsilon: 0.6900935609921609\n",
            "Episode 74, Total Reward: 2, Epsilon: 0.6866430931872001\n",
            "Episode 75, Total Reward: -1, Epsilon: 0.6832098777212641\n",
            "Episode 76, Total Reward: -15, Epsilon: 0.6797938283326578\n",
            "Episode 77, Total Reward: -10, Epsilon: 0.6763948591909945\n",
            "Episode 78, Total Reward: -3, Epsilon: 0.6730128848950395\n",
            "Episode 79, Total Reward: -17, Epsilon: 0.6696478204705644\n",
            "Episode 80, Path: [[0, 0], [0, 1], [0, 2], [0, 3], [0, 4], [0, 4], [0, 3], [1, 3], [1, 2], [1, 3], [2, 3], [2, 4], [3, 4], [3, 3], [3, 4], [2, 4], [2, 4], [2, 4], [2, 4], [3, 4], [2, 4], [1, 4], [2, 4], [3, 4], [4, 4]]\n",
            "Episode 80, Total Reward: -13, Epsilon: 0.6662995813682115\n",
            "Episode 81, Total Reward: -2, Epsilon: 0.6629680834613705\n",
            "Episode 82, Total Reward: -17, Epsilon: 0.6596532430440636\n",
            "Episode 83, Total Reward: -3, Epsilon: 0.6563549768288433\n",
            "Episode 84, Total Reward: -6, Epsilon: 0.653073201944699\n",
            "Episode 85, Total Reward: -14, Epsilon: 0.6498078359349755\n",
            "Episode 86, Total Reward: 2, Epsilon: 0.6465587967553006\n",
            "Episode 87, Total Reward: -1, Epsilon: 0.6433260027715241\n",
            "Episode 88, Total Reward: -8, Epsilon: 0.6401093727576664\n",
            "Episode 89, Total Reward: -2, Epsilon: 0.6369088258938781\n",
            "Episode 90, Total Reward: -4, Epsilon: 0.6337242817644086\n",
            "Episode 91, Total Reward: -3, Epsilon: 0.6305556603555866\n",
            "Episode 92, Total Reward: -2, Epsilon: 0.6274028820538087\n",
            "Episode 93, Total Reward: -7, Epsilon: 0.6242658676435396\n",
            "Episode 94, Total Reward: -4, Epsilon: 0.6211445383053219\n",
            "Episode 95, Total Reward: -24, Epsilon: 0.6180388156137953\n",
            "Episode 96, Total Reward: -46, Epsilon: 0.6149486215357263\n",
            "Episode 97, Total Reward: -3, Epsilon: 0.6118738784280476\n",
            "Episode 98, Total Reward: -19, Epsilon: 0.6088145090359074\n",
            "Episode 99, Total Reward: -9, Epsilon: 0.6057704364907278\n",
            "Episode 100, Path: [[0, 0], [0, 0], [0, 1], [1, 1], [1, 0], [1, 1], [1, 0], [2, 0], [3, 0], [3, 1], [3, 0], [4, 0], [4, 1], [4, 2], [3, 2], [3, 3], [4, 3], [4, 4]]\n",
            "Episode 100, Total Reward: -6, Epsilon: 0.6027415843082742\n",
            "Episode 101, Total Reward: -14, Epsilon: 0.5997278763867329\n",
            "Episode 102, Total Reward: -31, Epsilon: 0.5967292370047992\n",
            "Episode 103, Total Reward: -14, Epsilon: 0.5937455908197752\n",
            "Episode 104, Total Reward: -3, Epsilon: 0.5907768628656763\n",
            "Episode 105, Total Reward: -6, Epsilon: 0.5878229785513479\n",
            "Episode 106, Total Reward: -11, Epsilon: 0.5848838636585911\n",
            "Episode 107, Total Reward: -3, Epsilon: 0.5819594443402982\n",
            "Episode 108, Total Reward: -5, Epsilon: 0.5790496471185967\n",
            "Episode 109, Total Reward: 1, Epsilon: 0.5761543988830038\n",
            "Episode 110, Total Reward: -19, Epsilon: 0.5732736268885887\n",
            "Episode 111, Total Reward: -10, Epsilon: 0.5704072587541458\n",
            "Episode 112, Total Reward: 0, Epsilon: 0.567555222460375\n",
            "Episode 113, Total Reward: -7, Epsilon: 0.5647174463480732\n",
            "Episode 114, Total Reward: -28, Epsilon: 0.5618938591163328\n",
            "Episode 115, Total Reward: -11, Epsilon: 0.5590843898207511\n",
            "Episode 116, Total Reward: -3, Epsilon: 0.5562889678716474\n",
            "Episode 117, Total Reward: -17, Epsilon: 0.5535075230322891\n",
            "Episode 118, Total Reward: 0, Epsilon: 0.5507399854171277\n",
            "Episode 119, Total Reward: -10, Epsilon: 0.547986285490042\n",
            "Episode 120, Path: [[0, 0], [0, 1], [1, 1], [1, 2], [1, 3], [2, 3], [2, 4], [3, 4], [3, 3], [3, 4], [2, 4], [2, 4], [3, 4], [2, 4], [2, 4], [2, 3], [1, 3], [2, 3], [3, 3], [3, 2], [4, 2], [4, 1], [4, 2], [4, 3], [3, 3], [3, 4], [4, 4]]\n",
            "Episode 120, Total Reward: -15, Epsilon: 0.5452463540625918\n",
            "Episode 121, Total Reward: -1, Epsilon: 0.5425201222922789\n",
            "Episode 122, Total Reward: 0, Epsilon: 0.5398075216808175\n",
            "Episode 123, Total Reward: -2, Epsilon: 0.5371084840724134\n",
            "Episode 124, Total Reward: -6, Epsilon: 0.5344229416520513\n",
            "Episode 125, Total Reward: -4, Epsilon: 0.531750826943791\n",
            "Episode 126, Total Reward: -4, Epsilon: 0.5290920728090721\n",
            "Episode 127, Total Reward: -13, Epsilon: 0.5264466124450268\n",
            "Episode 128, Total Reward: -5, Epsilon: 0.5238143793828016\n",
            "Episode 129, Total Reward: -5, Epsilon: 0.5211953074858876\n",
            "Episode 130, Total Reward: 2, Epsilon: 0.5185893309484582\n",
            "Episode 131, Total Reward: -4, Epsilon: 0.5159963842937159\n",
            "Episode 132, Total Reward: 1, Epsilon: 0.5134164023722473\n",
            "Episode 133, Total Reward: 3, Epsilon: 0.510849320360386\n",
            "Episode 134, Total Reward: 0, Epsilon: 0.5082950737585841\n",
            "Episode 135, Total Reward: -2, Epsilon: 0.5057535983897912\n",
            "Episode 136, Total Reward: -16, Epsilon: 0.5032248303978422\n",
            "Episode 137, Total Reward: -3, Epsilon: 0.500708706245853\n",
            "Episode 138, Total Reward: -15, Epsilon: 0.4982051627146237\n",
            "Episode 139, Total Reward: 1, Epsilon: 0.49571413690105054\n",
            "Episode 140, Path: [[0, 0], [0, 1], [0, 1], [1, 1], [1, 0], [1, 1], [0, 1], [0, 0], [0, 1], [0, 0], [0, 1], [0, 0], [0, 1], [0, 2], [0, 3], [1, 3], [0, 3], [1, 3], [0, 3], [1, 3], [1, 4], [0, 4], [1, 4], [1, 3], [0, 3], [0, 2], [0, 3], [0, 4], [0, 3], [0, 4], [0, 4], [1, 4], [2, 4], [1, 4], [2, 4], [3, 4], [4, 4]]\n",
            "Episode 140, Total Reward: -25, Epsilon: 0.4932355662165453\n",
            "Episode 141, Total Reward: -8, Epsilon: 0.4907693883854626\n",
            "Episode 142, Total Reward: 1, Epsilon: 0.4883155414435353\n",
            "Episode 143, Total Reward: -2, Epsilon: 0.4858739637363176\n",
            "Episode 144, Total Reward: -5, Epsilon: 0.483444593917636\n",
            "Episode 145, Total Reward: -1, Epsilon: 0.4810273709480478\n",
            "Episode 146, Total Reward: -1, Epsilon: 0.47862223409330756\n",
            "Episode 147, Total Reward: 0, Epsilon: 0.47622912292284103\n",
            "Episode 148, Total Reward: -25, Epsilon: 0.4738479773082268\n",
            "Episode 149, Total Reward: -5, Epsilon: 0.47147873742168567\n",
            "Episode 150, Total Reward: 2, Epsilon: 0.46912134373457726\n",
            "Episode 151, Total Reward: -1, Epsilon: 0.46677573701590436\n",
            "Episode 152, Total Reward: 0, Epsilon: 0.46444185833082485\n",
            "Episode 153, Total Reward: -1, Epsilon: 0.46211964903917074\n",
            "Episode 154, Total Reward: -2, Epsilon: 0.4598090507939749\n",
            "Episode 155, Total Reward: -1, Epsilon: 0.457510005540005\n",
            "Episode 156, Total Reward: -35, Epsilon: 0.45522245551230495\n",
            "Episode 157, Total Reward: -10, Epsilon: 0.4529463432347434\n",
            "Episode 158, Total Reward: -1, Epsilon: 0.4506816115185697\n",
            "Episode 159, Total Reward: -3, Epsilon: 0.4484282034609769\n",
            "Episode 160, Path: [[0, 0], [0, 1], [0, 2], [0, 3], [0, 2], [0, 3], [1, 3], [2, 3], [3, 3], [3, 4], [4, 4]]\n",
            "Episode 160, Total Reward: 1, Epsilon: 0.446186062443672\n",
            "Episode 161, Total Reward: -1, Epsilon: 0.4439551321314536\n",
            "Episode 162, Total Reward: -4, Epsilon: 0.4417353564707963\n",
            "Episode 163, Total Reward: -3, Epsilon: 0.43952667968844233\n",
            "Episode 164, Total Reward: -1, Epsilon: 0.43732904629000013\n",
            "Episode 165, Total Reward: 1, Epsilon: 0.4351424010585501\n",
            "Episode 166, Total Reward: 1, Epsilon: 0.43296668905325736\n",
            "Episode 167, Total Reward: -10, Epsilon: 0.43080185560799106\n",
            "Episode 168, Total Reward: -1, Epsilon: 0.4286478463299511\n",
            "Episode 169, Total Reward: -1, Epsilon: 0.42650460709830135\n",
            "Episode 170, Total Reward: -1, Epsilon: 0.42437208406280985\n",
            "Episode 171, Total Reward: -8, Epsilon: 0.4222502236424958\n",
            "Episode 172, Total Reward: -4, Epsilon: 0.42013897252428334\n",
            "Episode 173, Total Reward: -1, Epsilon: 0.4180382776616619\n",
            "Episode 174, Total Reward: 3, Epsilon: 0.4159480862733536\n",
            "Episode 175, Total Reward: -3, Epsilon: 0.41386834584198684\n",
            "Episode 176, Total Reward: -1, Epsilon: 0.4117990041127769\n",
            "Episode 177, Total Reward: -1, Epsilon: 0.40974000909221303\n",
            "Episode 178, Total Reward: -2, Epsilon: 0.40769130904675194\n",
            "Episode 179, Total Reward: -4, Epsilon: 0.40565285250151817\n",
            "Episode 180, Path: [[0, 0], [0, 1], [0, 2], [0, 3], [1, 3], [1, 2], [1, 3], [1, 4], [1, 3], [1, 4], [0, 4], [1, 4], [2, 4], [3, 4], [3, 4], [2, 4], [3, 4], [4, 4]]\n",
            "Episode 180, Total Reward: -6, Epsilon: 0.4036245882390106\n",
            "Episode 181, Total Reward: -11, Epsilon: 0.4016064652978155\n",
            "Episode 182, Total Reward: 3, Epsilon: 0.3995984329713264\n",
            "Episode 183, Total Reward: -4, Epsilon: 0.3976004408064698\n",
            "Episode 184, Total Reward: 1, Epsilon: 0.39561243860243744\n",
            "Episode 185, Total Reward: 1, Epsilon: 0.3936343764094253\n",
            "Episode 186, Total Reward: 2, Epsilon: 0.39166620452737816\n",
            "Episode 187, Total Reward: 0, Epsilon: 0.3897078735047413\n",
            "Episode 188, Total Reward: 3, Epsilon: 0.3877593341372176\n",
            "Episode 189, Total Reward: -3, Epsilon: 0.3858205374665315\n",
            "Episode 190, Total Reward: -7, Epsilon: 0.38389143477919885\n",
            "Episode 191, Total Reward: -3, Epsilon: 0.3819719776053028\n",
            "Episode 192, Total Reward: -9, Epsilon: 0.3800621177172763\n",
            "Episode 193, Total Reward: -4, Epsilon: 0.37816180712868996\n",
            "Episode 194, Total Reward: -2, Epsilon: 0.37627099809304654\n",
            "Episode 195, Total Reward: -4, Epsilon: 0.3743896431025813\n",
            "Episode 196, Total Reward: 2, Epsilon: 0.37251769488706843\n",
            "Episode 197, Total Reward: -1, Epsilon: 0.3706551064126331\n",
            "Episode 198, Total Reward: -1, Epsilon: 0.36880183088056995\n",
            "Episode 199, Total Reward: 1, Epsilon: 0.3669578217261671\n",
            "Episode 200, Path: [[0, 0], [1, 0], [1, 1], [2, 1], [2, 0], [2, 1], [2, 2], [2, 3], [2, 2], [1, 2], [1, 1], [2, 1], [3, 1], [2, 1], [2, 0], [2, 1], [2, 2], [2, 3], [3, 3], [2, 3], [3, 3], [3, 2], [4, 2], [4, 3], [4, 4]]\n",
            "Episode 200, Total Reward: -13, Epsilon: 0.36512303261753626\n",
            "Episode 201, Total Reward: -10, Epsilon: 0.3632974174544486\n",
            "Episode 202, Total Reward: 2, Epsilon: 0.3614809303671764\n",
            "Episode 203, Total Reward: 1, Epsilon: 0.3596735257153405\n",
            "Episode 204, Total Reward: 0, Epsilon: 0.3578751580867638\n",
            "Episode 205, Total Reward: 3, Epsilon: 0.35608578229633\n",
            "Episode 206, Total Reward: 0, Epsilon: 0.3543053533848483\n",
            "Episode 207, Total Reward: 1, Epsilon: 0.35253382661792404\n",
            "Episode 208, Total Reward: 3, Epsilon: 0.3507711574848344\n",
            "Episode 209, Total Reward: 3, Epsilon: 0.34901730169741024\n",
            "Episode 210, Total Reward: 3, Epsilon: 0.3472722151889232\n",
            "Episode 211, Total Reward: -15, Epsilon: 0.3455358541129786\n",
            "Episode 212, Total Reward: 1, Epsilon: 0.3438081748424137\n",
            "Episode 213, Total Reward: 3, Epsilon: 0.3420891339682016\n",
            "Episode 214, Total Reward: -2, Epsilon: 0.3403786882983606\n",
            "Episode 215, Total Reward: 1, Epsilon: 0.3386767948568688\n",
            "Episode 216, Total Reward: -4, Epsilon: 0.33698341088258443\n",
            "Episode 217, Total Reward: 1, Epsilon: 0.3352984938281715\n",
            "Episode 218, Total Reward: 1, Epsilon: 0.33362200135903064\n",
            "Episode 219, Total Reward: -1, Epsilon: 0.33195389135223546\n",
            "Episode 220, Path: [[0, 0], [1, 0], [1, 1], [1, 2], [2, 2], [2, 3], [3, 3], [4, 3], [4, 4]]\n",
            "Episode 220, Total Reward: 3, Epsilon: 0.3302941218954743\n",
            "Episode 221, Total Reward: 3, Epsilon: 0.32864265128599696\n",
            "Episode 222, Total Reward: 3, Epsilon: 0.326999438029567\n",
            "Episode 223, Total Reward: 1, Epsilon: 0.3253644408394192\n",
            "Episode 224, Total Reward: -3, Epsilon: 0.3237376186352221\n",
            "Episode 225, Total Reward: -3, Epsilon: 0.322118930542046\n",
            "Episode 226, Total Reward: 1, Epsilon: 0.32050833588933575\n",
            "Episode 227, Total Reward: -1, Epsilon: 0.31890579420988907\n",
            "Episode 228, Total Reward: -9, Epsilon: 0.3173112652388396\n",
            "Episode 229, Total Reward: 2, Epsilon: 0.3157247089126454\n",
            "Episode 230, Total Reward: 0, Epsilon: 0.3141460853680822\n",
            "Episode 231, Total Reward: 3, Epsilon: 0.3125753549412418\n",
            "Episode 232, Total Reward: 2, Epsilon: 0.31101247816653554\n",
            "Episode 233, Total Reward: 1, Epsilon: 0.30945741577570285\n",
            "Episode 234, Total Reward: 1, Epsilon: 0.3079101286968243\n",
            "Episode 235, Total Reward: 3, Epsilon: 0.3063705780533402\n",
            "Episode 236, Total Reward: -1, Epsilon: 0.30483872516307353\n",
            "Episode 237, Total Reward: -1, Epsilon: 0.3033145315372582\n",
            "Episode 238, Total Reward: -4, Epsilon: 0.3017979588795719\n",
            "Episode 239, Total Reward: 2, Epsilon: 0.30028896908517405\n",
            "Episode 240, Path: [[0, 0], [0, 1], [1, 1], [2, 1], [2, 2], [3, 2], [3, 3], [3, 4], [4, 4]]\n",
            "Episode 240, Total Reward: 3, Epsilon: 0.2987875242397482\n",
            "Episode 241, Total Reward: 1, Epsilon: 0.29729358661854943\n",
            "Episode 242, Total Reward: 3, Epsilon: 0.29580711868545667\n",
            "Episode 243, Total Reward: 1, Epsilon: 0.2943280830920294\n",
            "Episode 244, Total Reward: 3, Epsilon: 0.29285644267656924\n",
            "Episode 245, Total Reward: 0, Epsilon: 0.2913921604631864\n",
            "Episode 246, Total Reward: 1, Epsilon: 0.28993519966087045\n",
            "Episode 247, Total Reward: 0, Epsilon: 0.2884855236625661\n",
            "Episode 248, Total Reward: 3, Epsilon: 0.28704309604425327\n",
            "Episode 249, Total Reward: 0, Epsilon: 0.285607880564032\n",
            "Episode 250, Total Reward: 3, Epsilon: 0.28417984116121187\n",
            "Episode 251, Total Reward: -3, Epsilon: 0.2827589419554058\n",
            "Episode 252, Total Reward: -4, Epsilon: 0.28134514724562876\n",
            "Episode 253, Total Reward: 3, Epsilon: 0.2799384215094006\n",
            "Episode 254, Total Reward: 3, Epsilon: 0.27853872940185365\n",
            "Episode 255, Total Reward: 3, Epsilon: 0.27714603575484437\n",
            "Episode 256, Total Reward: 1, Epsilon: 0.2757603055760701\n",
            "Episode 257, Total Reward: -3, Epsilon: 0.2743815040481898\n",
            "Episode 258, Total Reward: -5, Epsilon: 0.2730095965279488\n",
            "Episode 259, Total Reward: 0, Epsilon: 0.27164454854530906\n",
            "Episode 260, Path: [[0, 0], [1, 0], [2, 0], [2, 1], [1, 1], [2, 1], [2, 2], [3, 2], [3, 3], [4, 3], [4, 4]]\n",
            "Episode 260, Total Reward: 1, Epsilon: 0.2702863258025825\n",
            "Episode 261, Total Reward: 3, Epsilon: 0.2689348941735696\n",
            "Episode 262, Total Reward: 1, Epsilon: 0.26759021970270175\n",
            "Episode 263, Total Reward: -1, Epsilon: 0.2662522686041882\n",
            "Episode 264, Total Reward: 3, Epsilon: 0.2649210072611673\n",
            "Episode 265, Total Reward: 1, Epsilon: 0.26359640222486147\n",
            "Episode 266, Total Reward: 3, Epsilon: 0.26227842021373715\n",
            "Episode 267, Total Reward: 3, Epsilon: 0.2609670281126685\n",
            "Episode 268, Total Reward: -5, Epsilon: 0.25966219297210513\n",
            "Episode 269, Total Reward: 2, Epsilon: 0.2583638820072446\n",
            "Episode 270, Total Reward: 1, Epsilon: 0.2570720625972084\n",
            "Episode 271, Total Reward: 1, Epsilon: 0.25578670228422234\n",
            "Episode 272, Total Reward: 2, Epsilon: 0.25450776877280124\n",
            "Episode 273, Total Reward: 2, Epsilon: 0.2532352299289372\n",
            "Episode 274, Total Reward: 3, Epsilon: 0.2519690537792925\n",
            "Episode 275, Total Reward: 1, Epsilon: 0.2507092085103961\n",
            "Episode 276, Total Reward: 3, Epsilon: 0.2494556624678441\n",
            "Episode 277, Total Reward: 1, Epsilon: 0.24820838415550486\n",
            "Episode 278, Total Reward: 3, Epsilon: 0.24696734223472733\n",
            "Episode 279, Total Reward: 3, Epsilon: 0.2457325055235537\n",
            "Episode 280, Path: [[0, 0], [0, 0], [1, 0], [1, 1], [2, 1], [2, 2], [3, 2], [3, 1], [3, 2], [3, 3], [4, 3], [4, 4]]\n",
            "Episode 280, Total Reward: 0, Epsilon: 0.24450384299593592\n",
            "Episode 281, Total Reward: 1, Epsilon: 0.24328132378095624\n",
            "Episode 282, Total Reward: 3, Epsilon: 0.24206491716205145\n",
            "Episode 283, Total Reward: 1, Epsilon: 0.2408545925762412\n",
            "Episode 284, Total Reward: 3, Epsilon: 0.23965031961336\n",
            "Episode 285, Total Reward: 3, Epsilon: 0.2384520680152932\n",
            "Episode 286, Total Reward: 1, Epsilon: 0.23725980767521673\n",
            "Episode 287, Total Reward: -1, Epsilon: 0.23607350863684065\n",
            "Episode 288, Total Reward: 1, Epsilon: 0.23489314109365644\n",
            "Episode 289, Total Reward: 3, Epsilon: 0.23371867538818816\n",
            "Episode 290, Total Reward: 3, Epsilon: 0.23255008201124722\n",
            "Episode 291, Total Reward: 1, Epsilon: 0.231387331601191\n",
            "Episode 292, Total Reward: 1, Epsilon: 0.23023039494318503\n",
            "Episode 293, Total Reward: 2, Epsilon: 0.2290792429684691\n",
            "Episode 294, Total Reward: -7, Epsilon: 0.22793384675362674\n",
            "Episode 295, Total Reward: -3, Epsilon: 0.22679417751985861\n",
            "Episode 296, Total Reward: -4, Epsilon: 0.22566020663225933\n",
            "Episode 297, Total Reward: 1, Epsilon: 0.22453190559909803\n",
            "Episode 298, Total Reward: 3, Epsilon: 0.22340924607110255\n",
            "Episode 299, Total Reward: 3, Epsilon: 0.22229219984074702\n",
            "Episode 300, Path: [[0, 0], [1, 0], [1, 1], [1, 2], [1, 3], [1, 4], [2, 4], [3, 4], [3, 3], [4, 3], [4, 2], [4, 3], [4, 4]]\n",
            "Episode 300, Total Reward: -1, Epsilon: 0.2211807388415433\n",
            "Episode 301, Total Reward: 1, Epsilon: 0.22007483514733558\n",
            "Episode 302, Total Reward: 0, Epsilon: 0.2189744609715989\n",
            "Episode 303, Total Reward: 3, Epsilon: 0.2178795886667409\n",
            "Episode 304, Total Reward: 0, Epsilon: 0.2167901907234072\n",
            "Episode 305, Total Reward: 3, Epsilon: 0.21570623976979014\n",
            "Episode 306, Total Reward: 3, Epsilon: 0.21462770857094118\n",
            "Episode 307, Total Reward: 2, Epsilon: 0.21355457002808648\n",
            "Episode 308, Total Reward: 1, Epsilon: 0.21248679717794605\n",
            "Episode 309, Total Reward: 1, Epsilon: 0.21142436319205632\n",
            "Episode 310, Total Reward: 2, Epsilon: 0.21036724137609603\n",
            "Episode 311, Total Reward: -1, Epsilon: 0.20931540516921554\n",
            "Episode 312, Total Reward: 2, Epsilon: 0.20826882814336947\n",
            "Episode 313, Total Reward: 3, Epsilon: 0.20722748400265262\n",
            "Episode 314, Total Reward: -1, Epsilon: 0.20619134658263935\n",
            "Episode 315, Total Reward: 1, Epsilon: 0.20516038984972615\n",
            "Episode 316, Total Reward: -1, Epsilon: 0.2041345879004775\n",
            "Episode 317, Total Reward: 2, Epsilon: 0.2031139149609751\n",
            "Episode 318, Total Reward: 1, Epsilon: 0.20209834538617025\n",
            "Episode 319, Total Reward: 0, Epsilon: 0.2010878536592394\n",
            "Episode 320, Path: [[0, 0], [1, 0], [1, 1], [2, 1], [3, 1], [3, 2], [3, 3], [3, 4], [4, 4]]\n",
            "Episode 320, Total Reward: 3, Epsilon: 0.2000824143909432\n",
            "Episode 321, Total Reward: 1, Epsilon: 0.19908200231898848\n",
            "Episode 322, Total Reward: 3, Epsilon: 0.19808659230739353\n",
            "Episode 323, Total Reward: 1, Epsilon: 0.19709615934585656\n",
            "Episode 324, Total Reward: 3, Epsilon: 0.19611067854912728\n",
            "Episode 325, Total Reward: 3, Epsilon: 0.19513012515638165\n",
            "Episode 326, Total Reward: 2, Epsilon: 0.19415447453059972\n",
            "Episode 327, Total Reward: -1, Epsilon: 0.19318370215794672\n",
            "Episode 328, Total Reward: 3, Epsilon: 0.192217783647157\n",
            "Episode 329, Total Reward: -1, Epsilon: 0.1912566947289212\n",
            "Episode 330, Total Reward: 3, Epsilon: 0.1903004112552766\n",
            "Episode 331, Total Reward: 1, Epsilon: 0.18934890919900021\n",
            "Episode 332, Total Reward: 3, Epsilon: 0.18840216465300522\n",
            "Episode 333, Total Reward: 2, Epsilon: 0.18746015382974018\n",
            "Episode 334, Total Reward: 3, Epsilon: 0.1865228530605915\n",
            "Episode 335, Total Reward: 3, Epsilon: 0.18559023879528855\n",
            "Episode 336, Total Reward: 1, Epsilon: 0.1846622876013121\n",
            "Episode 337, Total Reward: 3, Epsilon: 0.18373897616330553\n",
            "Episode 338, Total Reward: 3, Epsilon: 0.182820281282489\n",
            "Episode 339, Total Reward: 2, Epsilon: 0.18190617987607657\n",
            "Episode 340, Path: [[0, 0], [1, 0], [1, 0], [1, 1], [2, 1], [3, 1], [3, 2], [3, 3], [4, 3], [4, 4]]\n",
            "Episode 340, Total Reward: 2, Epsilon: 0.18099664897669618\n",
            "Episode 341, Total Reward: 1, Epsilon: 0.1800916657318127\n",
            "Episode 342, Total Reward: 1, Epsilon: 0.17919120740315364\n",
            "Episode 343, Total Reward: -1, Epsilon: 0.17829525136613786\n",
            "Episode 344, Total Reward: 3, Epsilon: 0.17740377510930716\n",
            "Episode 345, Total Reward: -1, Epsilon: 0.17651675623376062\n",
            "Episode 346, Total Reward: 3, Epsilon: 0.1756341724525918\n",
            "Episode 347, Total Reward: 3, Epsilon: 0.17475600159032884\n",
            "Episode 348, Total Reward: 3, Epsilon: 0.17388222158237718\n",
            "Episode 349, Total Reward: 2, Epsilon: 0.1730128104744653\n",
            "Episode 350, Total Reward: 3, Epsilon: 0.17214774642209296\n",
            "Episode 351, Total Reward: 2, Epsilon: 0.1712870076899825\n",
            "Episode 352, Total Reward: 3, Epsilon: 0.17043057265153258\n",
            "Episode 353, Total Reward: 0, Epsilon: 0.16957841978827493\n",
            "Episode 354, Total Reward: -5, Epsilon: 0.16873052768933355\n",
            "Episode 355, Total Reward: 1, Epsilon: 0.1678868750508869\n",
            "Episode 356, Total Reward: 3, Epsilon: 0.16704744067563246\n",
            "Episode 357, Total Reward: 3, Epsilon: 0.1662122034722543\n",
            "Episode 358, Total Reward: -1, Epsilon: 0.16538114245489302\n",
            "Episode 359, Total Reward: -1, Epsilon: 0.16455423674261854\n",
            "Episode 360, Path: [[0, 0], [0, 1], [1, 1], [1, 2], [2, 2], [2, 1], [3, 1], [3, 0], [3, 1], [3, 2], [3, 3], [3, 4], [4, 4]]\n",
            "Episode 360, Total Reward: -1, Epsilon: 0.16373146555890544\n",
            "Episode 361, Total Reward: 3, Epsilon: 0.16291280823111093\n",
            "Episode 362, Total Reward: 3, Epsilon: 0.16209824418995536\n",
            "Episode 363, Total Reward: 2, Epsilon: 0.16128775296900558\n",
            "Episode 364, Total Reward: 1, Epsilon: 0.16048131420416054\n",
            "Episode 365, Total Reward: 3, Epsilon: 0.15967890763313974\n",
            "Episode 366, Total Reward: -2, Epsilon: 0.15888051309497406\n",
            "Episode 367, Total Reward: -1, Epsilon: 0.1580861105294992\n",
            "Episode 368, Total Reward: -1, Epsilon: 0.1572956799768517\n",
            "Episode 369, Total Reward: -1, Epsilon: 0.15650920157696743\n",
            "Episode 370, Total Reward: 3, Epsilon: 0.1557266555690826\n",
            "Episode 371, Total Reward: -5, Epsilon: 0.1549480222912372\n",
            "Episode 372, Total Reward: 1, Epsilon: 0.15417328217978102\n",
            "Episode 373, Total Reward: -1, Epsilon: 0.1534024157688821\n",
            "Episode 374, Total Reward: 3, Epsilon: 0.1526354036900377\n",
            "Episode 375, Total Reward: 1, Epsilon: 0.1518722266715875\n",
            "Episode 376, Total Reward: -2, Epsilon: 0.15111286553822956\n",
            "Episode 377, Total Reward: 1, Epsilon: 0.15035730121053842\n",
            "Episode 378, Total Reward: 3, Epsilon: 0.14960551470448571\n",
            "Episode 379, Total Reward: 3, Epsilon: 0.14885748713096328\n",
            "Episode 380, Path: [[0, 0], [1, 0], [2, 0], [3, 0], [3, 0], [3, 1], [4, 1], [4, 2], [4, 3], [4, 4]]\n",
            "Episode 380, Total Reward: 2, Epsilon: 0.14811319969530845\n",
            "Episode 381, Total Reward: -1, Epsilon: 0.1473726336968319\n",
            "Episode 382, Total Reward: 3, Epsilon: 0.14663577052834775\n",
            "Episode 383, Total Reward: 1, Epsilon: 0.14590259167570602\n",
            "Episode 384, Total Reward: 2, Epsilon: 0.1451730787173275\n",
            "Episode 385, Total Reward: 3, Epsilon: 0.14444721332374086\n",
            "Episode 386, Total Reward: 1, Epsilon: 0.14372497725712216\n",
            "Episode 387, Total Reward: 1, Epsilon: 0.14300635237083656\n",
            "Episode 388, Total Reward: 3, Epsilon: 0.14229132060898236\n",
            "Episode 389, Total Reward: 3, Epsilon: 0.14157986400593744\n",
            "Episode 390, Total Reward: 2, Epsilon: 0.14087196468590776\n",
            "Episode 391, Total Reward: 1, Epsilon: 0.14016760486247823\n",
            "Episode 392, Total Reward: -1, Epsilon: 0.13946676683816583\n",
            "Episode 393, Total Reward: 3, Epsilon: 0.138769433003975\n",
            "Episode 394, Total Reward: 3, Epsilon: 0.13807558583895513\n",
            "Episode 395, Total Reward: 1, Epsilon: 0.13738520790976036\n",
            "Episode 396, Total Reward: 1, Epsilon: 0.13669828187021155\n",
            "Episode 397, Total Reward: 3, Epsilon: 0.13601479046086049\n",
            "Episode 398, Total Reward: 3, Epsilon: 0.1353347165085562\n",
            "Episode 399, Total Reward: 3, Epsilon: 0.1346580429260134\n",
            "Episode 400, Path: [[0, 0], [0, 1], [0, 2], [1, 2], [1, 3], [1, 2], [0, 2], [1, 2], [1, 3], [1, 4], [2, 4], [3, 4], [4, 4]]\n",
            "Episode 400, Total Reward: -1, Epsilon: 0.13398475271138335\n",
            "Episode 401, Total Reward: -1, Epsilon: 0.13331482894782642\n",
            "Episode 402, Total Reward: 1, Epsilon: 0.13264825480308728\n",
            "Episode 403, Total Reward: 3, Epsilon: 0.13198501352907185\n",
            "Episode 404, Total Reward: 3, Epsilon: 0.1313250884614265\n",
            "Episode 405, Total Reward: 1, Epsilon: 0.13066846301911936\n",
            "Episode 406, Total Reward: 3, Epsilon: 0.13001512070402377\n",
            "Episode 407, Total Reward: 1, Epsilon: 0.12936504510050365\n",
            "Episode 408, Total Reward: 1, Epsilon: 0.12871821987500112\n",
            "Episode 409, Total Reward: 3, Epsilon: 0.12807462877562611\n",
            "Episode 410, Total Reward: 0, Epsilon: 0.12743425563174798\n",
            "Episode 411, Total Reward: 3, Epsilon: 0.12679708435358925\n",
            "Episode 412, Total Reward: -5, Epsilon: 0.1261630989318213\n",
            "Episode 413, Total Reward: 1, Epsilon: 0.1255322834371622\n",
            "Episode 414, Total Reward: 3, Epsilon: 0.12490462201997637\n",
            "Episode 415, Total Reward: 3, Epsilon: 0.1242800989098765\n",
            "Episode 416, Total Reward: 1, Epsilon: 0.12365869841532712\n",
            "Episode 417, Total Reward: 3, Epsilon: 0.12304040492325048\n",
            "Episode 418, Total Reward: 3, Epsilon: 0.12242520289863423\n",
            "Episode 419, Total Reward: 3, Epsilon: 0.12181307688414106\n",
            "Episode 420, Path: [[0, 0], [1, 0], [1, 1], [1, 2], [1, 3], [1, 4], [2, 4], [3, 4], [4, 4]]\n",
            "Episode 420, Total Reward: 3, Epsilon: 0.12120401149972035\n",
            "Episode 421, Total Reward: 3, Epsilon: 0.12059799144222175\n",
            "Episode 422, Total Reward: 3, Epsilon: 0.11999500148501063\n",
            "Episode 423, Total Reward: 3, Epsilon: 0.11939502647758558\n",
            "Episode 424, Total Reward: 1, Epsilon: 0.11879805134519765\n",
            "Episode 425, Total Reward: 3, Epsilon: 0.11820406108847166\n",
            "Episode 426, Total Reward: 1, Epsilon: 0.1176130407830293\n",
            "Episode 427, Total Reward: 3, Epsilon: 0.11702497557911415\n",
            "Episode 428, Total Reward: 3, Epsilon: 0.11643985070121858\n",
            "Episode 429, Total Reward: 1, Epsilon: 0.11585765144771248\n",
            "Episode 430, Total Reward: 3, Epsilon: 0.11527836319047392\n",
            "Episode 431, Total Reward: 3, Epsilon: 0.11470197137452155\n",
            "Episode 432, Total Reward: 3, Epsilon: 0.11412846151764894\n",
            "Episode 433, Total Reward: -2, Epsilon: 0.1135578192100607\n",
            "Episode 434, Total Reward: 0, Epsilon: 0.11299003011401039\n",
            "Episode 435, Total Reward: 3, Epsilon: 0.11242507996344034\n",
            "Episode 436, Total Reward: 3, Epsilon: 0.11186295456362313\n",
            "Episode 437, Total Reward: 3, Epsilon: 0.11130363979080501\n",
            "Episode 438, Total Reward: 3, Epsilon: 0.11074712159185099\n",
            "Episode 439, Total Reward: 3, Epsilon: 0.11019338598389174\n",
            "Episode 440, Path: [[0, 0], [0, 1], [0, 2], [0, 3], [1, 3], [2, 3], [3, 3], [3, 4], [4, 4]]\n",
            "Episode 440, Total Reward: 3, Epsilon: 0.10964241905397228\n",
            "Episode 441, Total Reward: 3, Epsilon: 0.10909420695870241\n",
            "Episode 442, Total Reward: 3, Epsilon: 0.1085487359239089\n",
            "Episode 443, Total Reward: 2, Epsilon: 0.10800599224428936\n",
            "Episode 444, Total Reward: 1, Epsilon: 0.10746596228306791\n",
            "Episode 445, Total Reward: 3, Epsilon: 0.10692863247165257\n",
            "Episode 446, Total Reward: 3, Epsilon: 0.1063939893092943\n",
            "Episode 447, Total Reward: 3, Epsilon: 0.10586201936274783\n",
            "Episode 448, Total Reward: 3, Epsilon: 0.10533270926593409\n",
            "Episode 449, Total Reward: -1, Epsilon: 0.10480604571960442\n",
            "Episode 450, Total Reward: 0, Epsilon: 0.1042820154910064\n",
            "Episode 451, Total Reward: 1, Epsilon: 0.10376060541355137\n",
            "Episode 452, Total Reward: 3, Epsilon: 0.1032418023864836\n",
            "Episode 453, Total Reward: 1, Epsilon: 0.10272559337455119\n",
            "Episode 454, Total Reward: 3, Epsilon: 0.10221196540767843\n",
            "Episode 455, Total Reward: 3, Epsilon: 0.10170090558064004\n",
            "Episode 456, Total Reward: 0, Epsilon: 0.10119240105273684\n",
            "Episode 457, Total Reward: 3, Epsilon: 0.10068643904747315\n",
            "Episode 458, Total Reward: 3, Epsilon: 0.10018300685223579\n",
            "Episode 459, Total Reward: 3, Epsilon: 0.0996820918179746\n",
            "Episode 460, Path: [[0, 0], [1, 0], [2, 0], [2, 1], [2, 2], [3, 2], [3, 3], [3, 4], [4, 4]]\n",
            "Episode 460, Total Reward: 3, Epsilon: 0.09918368135888474\n",
            "Episode 461, Total Reward: 3, Epsilon: 0.09868776295209031\n",
            "Episode 462, Total Reward: 3, Epsilon: 0.09819432413732986\n",
            "Episode 463, Total Reward: 3, Epsilon: 0.09770335251664321\n",
            "Episode 464, Total Reward: 3, Epsilon: 0.09721483575406\n",
            "Episode 465, Total Reward: 1, Epsilon: 0.09672876157528969\n",
            "Episode 466, Total Reward: 3, Epsilon: 0.09624511776741324\n",
            "Episode 467, Total Reward: 3, Epsilon: 0.09576389217857617\n",
            "Episode 468, Total Reward: 1, Epsilon: 0.09528507271768329\n",
            "Episode 469, Total Reward: 3, Epsilon: 0.09480864735409487\n",
            "Episode 470, Total Reward: 1, Epsilon: 0.0943346041173244\n",
            "Episode 471, Total Reward: 3, Epsilon: 0.09386293109673778\n",
            "Episode 472, Total Reward: 3, Epsilon: 0.09339361644125409\n",
            "Episode 473, Total Reward: 3, Epsilon: 0.09292664835904782\n",
            "Episode 474, Total Reward: -1, Epsilon: 0.09246201511725258\n",
            "Episode 475, Total Reward: 3, Epsilon: 0.09199970504166631\n",
            "Episode 476, Total Reward: 3, Epsilon: 0.09153970651645797\n",
            "Episode 477, Total Reward: 3, Epsilon: 0.09108200798387568\n",
            "Episode 478, Total Reward: 0, Epsilon: 0.0906265979439563\n",
            "Episode 479, Total Reward: 1, Epsilon: 0.09017346495423652\n",
            "Episode 480, Path: [[0, 0], [1, 0], [2, 0], [3, 0], [3, 1], [3, 2], [3, 1], [3, 2], [3, 3], [4, 3], [4, 4]]\n",
            "Episode 480, Total Reward: 1, Epsilon: 0.08972259762946533\n",
            "Episode 481, Total Reward: 3, Epsilon: 0.089273984641318\n",
            "Episode 482, Total Reward: 3, Epsilon: 0.0888276147181114\n",
            "Episode 483, Total Reward: 1, Epsilon: 0.08838347664452084\n",
            "Episode 484, Total Reward: 3, Epsilon: 0.08794155926129824\n",
            "Episode 485, Total Reward: 1, Epsilon: 0.08750185146499175\n",
            "Episode 486, Total Reward: 1, Epsilon: 0.08706434220766679\n",
            "Episode 487, Total Reward: 3, Epsilon: 0.08662902049662846\n",
            "Episode 488, Total Reward: 3, Epsilon: 0.08619587539414532\n",
            "Episode 489, Total Reward: 3, Epsilon: 0.08576489601717459\n",
            "Episode 490, Total Reward: 2, Epsilon: 0.08533607153708872\n",
            "Episode 491, Total Reward: 3, Epsilon: 0.08490939117940327\n",
            "Episode 492, Total Reward: 3, Epsilon: 0.08448484422350626\n",
            "Episode 493, Total Reward: 3, Epsilon: 0.08406242000238873\n",
            "Episode 494, Total Reward: 0, Epsilon: 0.08364210790237678\n",
            "Episode 495, Total Reward: 3, Epsilon: 0.0832238973628649\n",
            "Episode 496, Total Reward: 3, Epsilon: 0.08280777787605056\n",
            "Episode 497, Total Reward: 1, Epsilon: 0.08239373898667031\n",
            "Episode 498, Total Reward: 3, Epsilon: 0.08198177029173696\n",
            "Episode 499, Total Reward: 3, Epsilon: 0.08157186144027828\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    train_dqn()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmfeYL2Unue4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}